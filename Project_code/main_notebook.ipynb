{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa5d9c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a1015d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row,Window\n",
    "from pyspark.sql.functions import *\n",
    "from utilities import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dca9b794",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrashAnalysis:\n",
    "    def __init__(self, path_to_config_file):\n",
    "        input_file_paths = utils.read_json(config_file_path)['INPUT_FILENAME']\n",
    "        self.df_charges = utils.read_csv_to_df(spark, input_file_paths[\"Charges\"])\n",
    "        self.df_damages = utils.read_csv_to_df(spark, input_file_paths[\"Damages\"])\n",
    "        self.df_endorse = utils.read_csv_to_df(spark, input_file_paths[\"Endorse\"])\n",
    "        self.df_primary_person = utils.read_csv_to_df(spark, input_file_paths[\"Primary_Person\"])\n",
    "        self.df_units = utils.read_csv_to_df(spark, input_file_paths[\"Units\"])\n",
    "        self.df_restrict = utils.read_csv_to_df(spark, input_file_paths[\"Restrict\"])\n",
    "    def fetch_count_male_accidents(self, output_path):\n",
    "        \"\"\"\n",
    "        1.Fetch number of crashes  in which number of persons killed are male\n",
    "        \"\"\"\n",
    "        df = self.df_primary_person.filter(self.df_primary_person.PRSN_GNDR_ID == \"MALE\").groupby().count()\n",
    "    \n",
    "        utils.write_output_in_parquet(df, output_path)\n",
    "        print(\"Output for Analysis 1 :\",[row[0] for row in df.collect()][0])\n",
    "    def fetch_count_2_wheeler_accidents(self, output_path):\n",
    "        \"\"\"\n",
    "        2.Fetch number of crashes where the vehicle type was 2 wheeler.\n",
    "        \"\"\"\n",
    "        \n",
    "        df = self.df_units.filter(self.df_units.VEH_BODY_STYL_ID.contains(\"MOTORCYCLE\")).groupby().count()\n",
    "        \n",
    "        utils.write_output_in_parquet(df, output_path)\n",
    "        print(\"Output for Analysis 2 :\",[row[0] for row in df.collect()][0])\n",
    "    def fetch_state_with_highest_female_accident(self, output_path):\n",
    "        \"\"\"\n",
    "        3.Fetch state name with Most accidents in which female are involved\n",
    "        \"\"\"\n",
    "        \n",
    "        df = self.df_primary_person.filter(self.df_primary_person.PRSN_GNDR_ID == \"FEMALE\"). \\\n",
    "                                    groupby(\"DRVR_LIC_STATE_ID\").count(). \\\n",
    "                                    sort(col(\"count\").desc()). \\\n",
    "                                    limit(1). \\\n",
    "                                    select(\"DRVR_LIC_STATE_ID\")\n",
    "        \n",
    "        utils.write_output_in_parquet(df,output_path)\n",
    "        print(\"Output for Analysis 3 :\",df.first().DRVR_LIC_STATE_ID)\n",
    "    def fetch_top_vehicle_contributing_to_injuries(self, output_path):\n",
    "        \"\"\"\n",
    "        4.Fetch Top 5th to 15th VEH_MAKE_IDs that contribute to a largest number of injuries including death\n",
    "        \"\"\"\n",
    "        \n",
    "        df = self.df_units.filter(self.df_units.VEH_MAKE_ID != \"NA\"). \\\n",
    "                           withColumn('TOT_CASUALTIES_CNT', self.df_units.TOT_INJRY_CNT+self.df_units.DEATH_CNT). \\\n",
    "                           groupby(\"VEH_MAKE_ID\").sum(\"TOT_CASUALTIES_CNT\"). \\\n",
    "                           withColumnRenamed(\"sum(TOT_CASUALTIES_CNT)\", \"TOT_CASUALTIES_CNT_AGG\"). \\\n",
    "                           sort(col(\"TOT_CASUALTIES_CNT_AGG\").desc()).\\\n",
    "                           limit(15).select(\"VEH_MAKE_ID\")\n",
    "        df_final=df.subtract(df.limit(5))\n",
    "        \n",
    "        utils.write_output_in_parquet(df_final, output_path)\n",
    "        print(\"Output for Analysis 4 :\",[ID[0] for ID in df_final.collect()])\n",
    "    def fetch_top_ethnic_ug_crash_for_each_body_style(self, output_path):\n",
    "        \"\"\"\n",
    "        5.top ethnic user group of each unique body style that was involved in crashes\n",
    "        \"\"\"\n",
    "        \n",
    "      \n",
    "        \n",
    "        df = self.df_units.join(self.df_primary_person, self.df_units.CRASH_ID == self.df_primary_person.CRASH_ID, how='inner'). \\\n",
    "                           filter(~self.df_units.VEH_BODY_STYL_ID.isin([\"NA\", \"UNKNOWN\", \"NOT REPORTED\",\"OTHER  (EXPLAIN IN NARRATIVE)\"])). \\\n",
    "                           filter(~self.df_primary_person.PRSN_ETHNICITY_ID.isin([\"NA\", \"UNKNOWN\"])). \\\n",
    "                           groupby(\"VEH_BODY_STYL_ID\", \"PRSN_ETHNICITY_ID\").count(). \\\n",
    "                           withColumn(\"row\", row_number().over(Window.partitionBy(\"VEH_BODY_STYL_ID\").orderBy(col(\"count\").desc()))). \\\n",
    "                           filter(col(\"row\") == 1). \\\n",
    "                           drop(\"row\", \"count\")\n",
    "        \n",
    "        utils.write_output_in_parquet(df, output_path)\n",
    "        print(\"Output for Analysis 5 :\")\n",
    "        df.show(truncate=False)\n",
    "    def fetch_top_5_zip_codes_with_alcohols_as_cf_for_crash(self, output_path):\n",
    "        \"\"\"\n",
    "        6.Finds top 5 Zip Codes with the highest number crashes with alcohols as the contributing factor to a crash\n",
    "        \"\"\"\n",
    "        df = self.df_units.join(self.df_primary_person,self.df_units.CRASH_ID == self.df_primary_person.CRASH_ID, how='inner'). \\\n",
    "                           dropna(subset=[\"DRVR_ZIP\"]). \\\n",
    "                           filter(col(\"CONTRIB_FACTR_1_ID\").contains(\"ALCOHOL\") | col(\"CONTRIB_FACTR_2_ID\").contains(\"ALCOHOL\")). \\\n",
    "                           groupby(\"DRVR_ZIP\").count().orderBy(col(\"count\").desc()).limit(5).select(\"DRVR_ZIP\")\n",
    "        \n",
    "        utils.write_output_in_parquet(df, output_path)\n",
    "        print(\"Output for Analysis 6 :\",[row[0] for row in df.collect()])\n",
    "    def fetch_crash_ids_with_no_damage(self, output_path):\n",
    "        \"\"\"\n",
    "        7.Counts Distinct Crash IDs where No Damaged Property was observed and Damage Level (VEH_DMAG_SCL~) is above 4\n",
    "        and car avails Insurance.\n",
    "        \"\"\"\n",
    "        df = self.df_damages.join(self.df_units, self.df_units.CRASH_ID == self.df_damages.CRASH_ID, how='inner'). \\\n",
    "                            filter(((self.df_units.VEH_DMAG_SCL_1_ID > \"DAMAGED 4\") &(~self.df_units.VEH_DMAG_SCL_1_ID.isin([\"NA\", \"NO DAMAGE\", \"INVALID VALUE\"]))) |\n",
    "                                   ((self.df_units.VEH_DMAG_SCL_2_ID > \"DAMAGED 4\") &(~self.df_units.VEH_DMAG_SCL_2_ID.isin([\"NA\", \"NO DAMAGE\", \"INVALID VALUE\"])))). \\\n",
    "                            filter(self.df_damages.DAMAGED_PROPERTY == \"NONE\"). \\\n",
    "                            filter(self.df_units.FIN_RESP_TYPE_ID == \"PROOF OF LIABILITY INSURANCE\"). \\\n",
    "                            select(self.df_units.CRASH_ID).distinct()\n",
    "        \n",
    "        utils.write_output_in_parquet(df, output_path)\n",
    "        print(\"Output for Analysis 7 :\",[row[0] for row in df.collect()])\n",
    "    def fetch_top_5_vehicle_brand(self, output_path):\n",
    "        \"\"\"\n",
    "        8.Determines the Top 5 Vehicle Brands where drivers are charged with speeding related offences, has licensed\n",
    "        Drivers, uses top 10 used vehicle colours and has car licensed with the Top 25 states with highest number of\n",
    "        offences\n",
    "        \"\"\"\n",
    "        df_top_25_state=self.df_units.filter(col(\"VEH_LIC_STATE_ID\").cast(\"int\").isNull()). \\\n",
    "                                      groupby(\"VEH_LIC_STATE_ID\").count(). \\\n",
    "                                      orderBy(col(\"count\").desc()).limit(25)\n",
    "        list_top_25_state = [row[0] for row in df_top_25_state.collect()]\n",
    "        \n",
    "        df_top_10_vehicle_colors = self.df_units.filter(self.df_units.VEH_COLOR_ID != \"NA\"). \\\n",
    "                                                 groupby(\"VEH_COLOR_ID\").count().orderBy(col(\"count\").desc()).limit(10)\n",
    "        list_top_10_vehicle_colors = [row[0] for row in df_top_10_vehicle_colors.collect()]\n",
    "\n",
    "        \n",
    "        df = self.df_charges.join(self.df_primary_person, self.df_primary_person.CRASH_ID == self.df_charges.CRASH_ID, how='inner'). \\\n",
    "                             join(self.df_units, self.df_units.CRASH_ID == self.df_charges.CRASH_ID, how='inner'). \\\n",
    "                             filter(self.df_charges.CHARGE.contains(\"SPEED\")). \\\n",
    "                             filter(self.df_primary_person.DRVR_LIC_TYPE_ID.isin([\"DRIVER LICENSE\", \"COMMERCIAL DRIVER LIC.\"])). \\\n",
    "                             filter(self.df_units.VEH_COLOR_ID.isin(list_top_10_vehicle_colors)). \\\n",
    "                             filter(self.df_units.VEH_LIC_STATE_ID.isin(list_top_25_state)). \\\n",
    "                             groupby(\"VEH_MAKE_ID\").count(). \\\n",
    "                             orderBy(col(\"count\").desc()).limit(5).select(\"VEH_MAKE_ID\")\n",
    "        \n",
    "        utils.write_output_in_parquet(df, output_path)\n",
    "        print(\"Output for Analysis 8 :\",[row[0] for row in df.collect()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd46f991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output for Analysis 1 : 96782\n",
      "Output for Analysis 2 : 784\n",
      "Output for Analysis 3 : Texas\n",
      "Output for Analysis 4 : ['HONDA', 'GMC', 'HYUNDAI', 'KIA', 'JEEP', 'CHRYSLER', 'MAZDA', 'VOLKSWAGEN', 'PONTIAC', 'LEXUS']\n",
      "Output for Analysis 5 :\n",
      "+---------------------------------+-----------------+\n",
      "|VEH_BODY_STYL_ID                 |PRSN_ETHNICITY_ID|\n",
      "+---------------------------------+-----------------+\n",
      "|AMBULANCE                        |WHITE            |\n",
      "|BUS                              |HISPANIC         |\n",
      "|FARM EQUIPMENT                   |WHITE            |\n",
      "|FIRE TRUCK                       |WHITE            |\n",
      "|MOTORCYCLE                       |WHITE            |\n",
      "|NEV-NEIGHBORHOOD ELECTRIC VEHICLE|WHITE            |\n",
      "|PASSENGER CAR, 2-DOOR            |WHITE            |\n",
      "|PASSENGER CAR, 4-DOOR            |WHITE            |\n",
      "|PICKUP                           |WHITE            |\n",
      "|POLICE CAR/TRUCK                 |WHITE            |\n",
      "|POLICE MOTORCYCLE                |HISPANIC         |\n",
      "|SPORT UTILITY VEHICLE            |WHITE            |\n",
      "|TRUCK                            |WHITE            |\n",
      "|TRUCK TRACTOR                    |WHITE            |\n",
      "|VAN                              |WHITE            |\n",
      "|YELLOW SCHOOL BUS                |WHITE            |\n",
      "+---------------------------------+-----------------+\n",
      "\n",
      "Output for Analysis 6 : ['76010', '78521', '75067', '78574', '75052']\n",
      "Output for Analysis 7 : [14870169, 14894076, 14996273, 15232090, 15249931, 15307513]\n",
      "Output for Analysis 8 : ['FORD', 'CHEVROLET', 'TOYOTA', 'DODGE', 'NISSAN']\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    spark = SparkSession.builder.appName(\"CrashAnalysis\").getOrCreate()\n",
    "    \n",
    "    config_file_path = \"config.json\"\n",
    "    \n",
    "    ca_obj = CrashAnalysis(config_file_path)\n",
    "    \n",
    "    output_paths = utils.read_json(config_file_path)['OUTPUT_PATH']\n",
    "    \n",
    "    #fetch result of Analysis1\n",
    "    ca_obj.fetch_count_male_accidents(output_paths['output_path_1'])\n",
    "    #fetch result of Analysis2\n",
    "    ca_obj.fetch_count_2_wheeler_accidents(output_paths['output_path_2'])\n",
    "    #fetch result of Analysis3\n",
    "    ca_obj.fetch_state_with_highest_female_accident(output_paths['output_path_3'])\n",
    "    #fetch result of Analysis4\n",
    "    ca_obj.fetch_top_vehicle_contributing_to_injuries(output_paths['output_path_4'])\n",
    "    #fetch result of Analysis5\n",
    "    ca_obj.fetch_top_ethnic_ug_crash_for_each_body_style(output_paths['output_path_5'])\n",
    "    #fetch result of Analysis6\n",
    "    ca_obj.fetch_top_5_zip_codes_with_alcohols_as_cf_for_crash(output_paths['output_path_6'])\n",
    "    #fetch result of Analysis7\n",
    "    ca_obj.fetch_crash_ids_with_no_damage(output_paths['output_path_7'])\n",
    "    #fetch result of Analysis8\n",
    "    ca_obj.fetch_top_5_vehicle_brand(output_paths['output_path_8'])\n",
    "    spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
